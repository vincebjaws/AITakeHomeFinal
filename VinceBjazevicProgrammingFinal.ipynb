{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lw8Ze4VfzTKJ"
      },
      "outputs": [],
      "source": [
        "# Author: Vince Bjazevic\n",
        "# Programing final\n",
        "\n",
        "\n",
        "from sys import last_type\n",
        "#Q1:\n",
        "from queue import PriorityQueue\n",
        "\n",
        "# Manahatan Distance\n",
        "def h(cell1, cell2):\n",
        "  y1, x1 = cell1\n",
        "  y2, x2 = cell2\n",
        "  return abs(x1-x2) + abs(y1-y2)\n",
        "\n",
        "#Grid\n",
        "grid = [(1,1),(1,2),(1,3),(1,4),(1,5),(1,6),(1,7),(1,8),(1,9),(1,10),(1,11),\n",
        "        (2,1),(2,2),(2,3),(2,4),(2,5),(2,6),(2,7),(2,8),(2,9),(2,10),(2,11),\n",
        "        (3,1),(3,2),(3,3),(3,4),(3,5),(3,6),(3,7),(3,8),(3,9),(3,10),(3,11),\n",
        "        (4,1),(4,2),(4,3),(4,4),(4,5),(4,6),(4,7),(4,8),(4,9),(4,10),(4,11),\n",
        "        (5,1),(5,2),(5,3),(5,4),(5,5),(5,6),(5,7),(5,8),(5,9),(5,10),(5,11),\n",
        "        (6,1),(6,2),(6,3),(6,4),(6,5),(6,6),(6,7),(6,8),(6,9),(6,10),(6,11),\n",
        "        (7,1),(7,2),(7,3),(7,4),(7,5),(7,6),(7,7),(7,8),(7,9),(7,10),(7,11),\n",
        "        (8,1),(8,2),(8,3),(8,4),(8,5),(8,6),(8,7),(8,8),(8,9),(8,10),(8,11),\n",
        "        (9,1),(9,2),(9,3),(9,4),(9,5),(9,6),(9,7),(9,8),(9,9),(9,10),(9,11),\n",
        "        (10,1),(10,2),(10,3),(10,4),(10,5),(10,6),(10,7),(10,8),(10,9),(10,10),(10,11),\n",
        "        (11,1),(11,2),(11,3),(11,4),(11,5),(11,6),(11,7),(11,8),(11,9),(11,10),(11,11)\n",
        "        ]\n",
        "\n",
        "# Grid with Alpha chars for readabbility\n",
        "grid_key = {\n",
        "        (1,1): ('A',1),(1,2): ('A',2),(1,3):('A',3),(1,4):('A',4),(1,5):('A',5),(1,6):('A',6),(1,7):('A',7),(1,8):('A',8),(1,9):('A',9),(1,10):('A',10),(1,11):('A',11),\n",
        "        (2,1): ('B',1),(2,2): ('B',2),(2,3):('B',3),(2,4):('B',4),(2,5):('B',5),(2,6):('B',6),(2,7):('B',7),(2,8):('A',8),(2,9):('B',9),(2,10):('B',10),(2,11):('B',11),\n",
        "        (3,1): ('C',1),(3,2): ('C',2),(3,3):('C',3),(3,4):('C',4),(3,5):('C',5),(3,6):('C',6),(3,7):('C',7),(3,8):('C',8),(3,9):('C',9),(3,10):('C',10),(3,11):('C',11),\n",
        "        (4,1): ('D',1),(4,2): ('D',2),(4,3):('D',3),(4,4):('D',4),(4,5):('D',5),(4,6):('D',6),(4,7):('D',7),(4,8):('D',8),(4,9):('D',9),(4,10):('D',10),(4,11):('D',11),\n",
        "        (5,1): ('E',1),(5,2): ('E',2),(5,3):('E',3),(5,4):('E',4),(5,5):('E',5),(5,6):('E',6),(5,7):('E',7),(5,8):('E',8),(5,9):('E',9),(5,10):('E',10),(5,11):('E',11),\n",
        "        (6,1): ('F',1),(6,2): ('F',2),(6,3):('F',3),(6,4):('F',4),(6,5):('F',5),(6,6):('F',6),(6,7):('F',7),(6,8):('F',8),(6,9):('F',9),(6,10):('F',10),(6,11):('F',11),\n",
        "        (7,1): ('G',1),(7,2): ('G',2),(7,3):('G',3),(7,4):('G',4),(7,5):('G',5),(7,6):('G',6),(7,7):('G',7),(7,8):('G',8),(7,9):('G',9),(7,10):('G',10),(7,11):('G',11),\n",
        "        (8,1): ('H',1),(8,2): ('H',2),(8,3):('H',3),(8,4):('H',4),(8,5):('H',5),(8,6):('H',6),(8,7):('H',7),(8,8):('H',8),(8,9):('H',9),(8,10):('H',10),(8,11):('H',11),\n",
        "        (9,1): ('I',1),(9,2): ('I',2),(9,3):('I',3),(9,4):('I',4),(9,5):('I',5),(9,6):('I',6),(9,7):('I',7),(9,8):('I',8),(9,9):('I',9),(9,10):('I',10),(9,11):('I',11),\n",
        "        (10,1): ('J',1),(10,2): ('J',2),(10,3):('J',3),(10,4):('J',4),(10,5):('J',5),(10,6):('J',6),(10,7):('J',7),(10,8):('J',8),(10,9):('J',9),(10,10):('J',10),(10,11):('J',11),\n",
        "        (11,1): ('K',1),(11,2): ('K',2),(11,3):('K',3),(11,4):('K',4),(11,5):('K',5),(11,6):('K',6),(11,7):('K',7),(11,8):('K',8),(11,9):('K',9),(11,10):('K',10),(11,11):('K',11)\n",
        "}\n",
        "\n",
        "# Dictionary of cells and traverse values 'EWNS'\n",
        "all_cells = {\n",
        "        (1,1): {'E':1,'W':0, 'N':0,'S':1},(1,2): {'E':1,'W':1, 'N':0,'S':0},\n",
        "        (1,3): {'E':0,'W':1, 'N':0,'S':1},(1,5): {'E':1,'W':0, 'N':0,'S':1},\n",
        "        (1,6): {'E':1,'W':1, 'N':0,'S':0},(1,7): {'E':1,'W':1, 'N':0,'S':0},\n",
        "        (1,8): {'E':1,'W':1, 'N':0,'S':0},(1,9): {'E':1,'W':1, 'N':0,'S':0},\n",
        "        (1,10): {'E':1,'W':1, 'N':0,'S':0},(1,11): {'E':0,'W':1, 'N':0,'S':1},\n",
        "        (2,1): {'E':0,'W':0, 'N':1,'S':1},(2,3): {'E':1,'W':0, 'N':1,'S':1},\n",
        "        (2,4): {'E':1,'W':1, 'N':0,'S':0},(2,5): {'E':0,'W':1, 'N':1,'S':1},\n",
        "        (2,11): {'E':0,'W':0, 'N':1,'S':1},(3,1): {'E':0,'W':0, 'N':1,'S':1},\n",
        "        (3,3): {'E':0,'W':0, 'N':1,'S':0},(3,5): {'E':0,'W':0, 'N':1,'S':0},\n",
        "        (3,7): {'E':1,'W':0, 'N':0,'S':0},(3,8): {'E':1,'W':1, 'N':0,'S':0},\n",
        "        (3,9): {'E':0,'W':1, 'N':0,'S':1},(3,11): {'E':0,'W':0, 'N':1,'S':1},\n",
        "        (4,1): {'E':0,'W':0, 'N':1,'S':1},(4,9): {'E':1,'W':0, 'N':1,'S':0},\n",
        "        (4,10): {'E':1,'W':1, 'N':0,'S':0},(4,11): {'E':0,'W':1, 'N':1,'S':1},\n",
        "        (5,1): {'E':0,'W':0, 'N':1,'S':0},(5,3): {'E':0,'W':0, 'N':0,'S':1},\n",
        "        (5,5): {'E':1,'W':0, 'N':0,'S':1},(5,6): {'E':1,'W':1, 'N':0,'S':0},\n",
        "        (5,7): {'E':0,'W':1, 'N':0,'S':1},(5,11): {'E':0,'W':0, 'N':1,'S':1},\n",
        "        (6,3): {'E':0,'W':0, 'N':1,'S':1},(6,5): {'E':0,'W':0, 'N':1,'S':0},\n",
        "        (6,7): {'E':0,'W':0, 'N':1,'S':1},(6,9): {'E':1,'W':0, 'N':0,'S':1},\n",
        "        (6,10): {'E':1,'W':1, 'N':0,'S':0},(6,11): {'E':0,'W':1, 'N':1,'S':0},\n",
        "        (7,1): {'E':1,'W':0, 'N':0,'S':1},(7,2): {'E':1,'W':1, 'N':0,'S':0},\n",
        "        (7,3): {'E':0,'W':1, 'N':1,'S':0},(7,7): {'E':1,'W':0, 'N':1,'S':1},\n",
        "        (7,8): {'E':1,'W':1, 'N':0,'S':0},(7,9): {'E':0,'W':1, 'N':1,'S':0},\n",
        "        (8,1): {'E':0,'W':0, 'N':1,'S':1},(8,5): {'E':0,'W':0, 'N':0,'S':1},\n",
        "        (8,7): {'E':0,'W':0, 'N':1,'S':1},(8,11): {'E':0,'W':0, 'N':0,'S':1},\n",
        "        (9,1): {'E':0,'W':0, 'N':1,'S':1},(9,3): {'E':1,'W':0, 'N':0,'S':1},\n",
        "        (9,4): {'E':1,'W':1, 'N':0,'S':0},(9,5): {'E':0,'W':1, 'N':1,'S':1},\n",
        "        (9,7): {'E':1,'W':0, 'N':1,'S':0},(9,8): {'E':1,'W':1, 'N':0,'S':0},\n",
        "        (9,9): {'E':0,'W':1, 'N':0,'S':1},(9,11): {'E':0,'W':0, 'N':1,'S':1},\n",
        "        (10,1): {'E':0,'W':0, 'N':1,'S':1},(10,3): {'E':0,'W':0, 'N':1,'S':1},\n",
        "        (10,5): {'E':0,'W':0, 'N':1,'S':1},(10,9): {'E':0,'W':0, 'N':1,'S':1},\n",
        "        (10,11): {'E':0,'W':0, 'N':1,'S':1},(11,1): {'E':1,'W':0, 'N':1,'S':0},\n",
        "        (11,2): {'E':1,'W':1, 'N':0,'S':0},(11,3): {'E':0,'W':1, 'N':1,'S':0},\n",
        "        (11,5): {'E':1,'W':0, 'N':1,'S':0},(11,6): {'E':1,'W':1, 'N':0,'S':0},\n",
        "        (11,7): {'E':1,'W':1, 'N':0,'S':0},(11,8): {'E':1,'W':1, 'N':0,'S':0},\n",
        "        (11,9): {'E':1,'W':1, 'N':1,'S':0},(11,10): {'E':1,'W':1, 'N':0,'S':0},\n",
        "        (11,11): {'E':0,'W':1, 'N':1,'S':0}}\n",
        "\n",
        "def print_path(start, goal, path):\n",
        "  print(grid_key[start], end=\"-->\")\n",
        "  for cell in reversed(path):\n",
        "    if path[cell] == goal:\n",
        "      print(grid_key[path[cell]])\n",
        "    else:\n",
        "      print(grid_key[path[cell]], end=\"-->\")\n",
        "\n",
        "# A*\n",
        "def A_Star(goal, start): #start = (y,x), goal = (y,x)\n",
        "\n",
        "  # Initializing a g() score and an f() score for each square on the grid\n",
        "  g_score = {cell:float('inf') for cell in grid}\n",
        "  g_score[start] = 0\n",
        "  f_score = {cell:float('inf') for cell in grid}\n",
        "  f_score[start] = h(start, goal)\n",
        "\n",
        "  # Priority Queue to exploritory store paths\n",
        "  open = PriorityQueue()\n",
        "  open.put((h(start, goal)+0,h(start,goal),start)) # Stored as (g+h --> fscore), heuristic, cell\n",
        "\n",
        "  # Creating dictionary for path storage\n",
        "  aPath = {}\n",
        "  while not open.empty():\n",
        "    currCell = open.get()[2] # grabs the current cell as a tuple\n",
        "    if currCell == goal: # End condition goal a has been met\n",
        "      break\n",
        "    for d in 'ESNW':\n",
        "      if all_cells[currCell][d]==True:\n",
        "        if d=='E':\n",
        "          childCell=(currCell[0], currCell[1]+1)\n",
        "        if d=='W':\n",
        "          childCell=(currCell[0], currCell[1]-1)\n",
        "        if d=='N':\n",
        "          childCell=(currCell[0]-1, currCell[1])\n",
        "        if d=='S':\n",
        "          childCell=(currCell[0]+1, currCell[1])\n",
        "\n",
        "        temp_g_score = g_score[currCell]+1\n",
        "        temp_f_score = temp_g_score+h(childCell,goal)\n",
        "        if temp_f_score < f_score[childCell]:\n",
        "          g_score[childCell] = temp_g_score\n",
        "          f_score[childCell] = temp_f_score\n",
        "          open.put((temp_f_score, h(childCell,goal),childCell))\n",
        "          aPath[childCell]=currCell\n",
        "\n",
        "  # Dictionary for storing optimal child: parent cell values\n",
        "  fwdPath = {}\n",
        "  cell = goal\n",
        "  while cell != start:\n",
        "    fwdPath[aPath[cell]]=cell\n",
        "    cell = aPath[cell]\n",
        "\n",
        "  # Returns traversal path (current_cell: previous_cell)\n",
        "  return fwdPath\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = (11,6)\n",
        "goal = (1, 6)\n",
        "path = A_Star(goal, start)\n",
        "\n",
        "print(\"Optimal Path is for Question 1 part 1 is:\")\n",
        "print_path(start, goal, path)\n",
        "start = (11,6)\n",
        "goal = (5, 3)\n",
        "path = A_Star(goal, start)\n",
        "\n",
        "print(\"Optimal Path is for Question 1 part 2 is:\")\n",
        "print_path(start, goal, path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEUHUNeamE7v",
        "outputId": "77f07dde-95fc-4f0d-a6cb-ea7217981154"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal Path is for Question 1 part 1 is:\n",
            "('K', 6)-->('K', 7)-->('K', 8)-->('K', 9)-->('J', 9)-->('I', 9)-->('I', 8)-->('I', 7)-->('H', 7)-->('G', 7)-->('G', 8)-->('G', 9)-->('F', 9)-->('F', 10)-->('F', 11)-->('E', 11)-->('D', 11)-->('C', 11)-->('B', 11)-->('A', 11)-->('A', 10)-->('A', 9)-->('A', 8)-->('A', 7)-->('A', 6)\n",
            "Optimal Path is for Question 1 part 2 is:\n",
            "('K', 6)-->('K', 5)-->('J', 5)-->('I', 5)-->('I', 4)-->('I', 3)-->('J', 3)-->('K', 3)-->('K', 2)-->('K', 1)-->('J', 1)-->('I', 1)-->('H', 1)-->('G', 1)-->('G', 2)-->('G', 3)-->('F', 3)-->('E', 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q2:\n",
        "import json\n",
        "\n",
        "class ticTacToeState:\n",
        "    def __init__(self,state,player,parent=None):\n",
        "        self.state = state\n",
        "        self.parent = parent\n",
        "        self.player = player\n",
        "        self.children = []\n",
        "\n",
        "#implement bfs on tictactoe(state,player) object\n",
        "def bfs(root_node):\n",
        "    #create queue and visited list\n",
        "    visited = []\n",
        "    queue = []\n",
        "    #create gametree for json output\n",
        "    tree = []\n",
        "    outs = set()\n",
        "    queue.append(root_node)\n",
        "\n",
        "    #while queue is not empty traverse laterally\n",
        "    while queue:\n",
        "        #remove root node\n",
        "        state_to_examine = queue.pop(0)\n",
        "        #check if not a repeating board state\n",
        "        board_state = state_to_examine.state\n",
        "        if board_state in visited:\n",
        "            continue\n",
        "        visited.append(state_to_examine)\n",
        "        #check if tree ends do to winner\n",
        "        if end_state(state_to_examine.state):\n",
        "            continue\n",
        "        #print current state\n",
        "        string_outs = \"\"\n",
        "        for n in state_to_examine.state:\n",
        "          if n == \"X\":\n",
        "            string_outs = string_outs+\"X\"\n",
        "          if n == \"O\":\n",
        "            string_outs = string_outs+\"O\"\n",
        "          if n == \" \":\n",
        "            string_outs = string_outs+\"-\"\n",
        "        tree.append({\"Current State\":state_to_examine.state})\n",
        "        outs.add(string_outs)\n",
        "        #get children of state\n",
        "        state_to_examine.children = create_new_states(state_to_examine.state, state_to_examine.player)\n",
        "        for i in range(len(state_to_examine.children)):\n",
        "          string_outs = \"\"\n",
        "          for j in state_to_examine.children[i].state:\n",
        "            if n == \"X\":\n",
        "              string_outs = string_outs+\"X\"\n",
        "            if n == \"O\":\n",
        "              string_outs = string_outs+\"O\"\n",
        "            if n == \" \":\n",
        "              string_outs = string_outs+\"-\"\n",
        "          outs.add(string_outs)\n",
        "        for i in range(len(state_to_examine.children)):\n",
        "            queue.append(state_to_examine.children[i])\n",
        "    return outs\n",
        "\n",
        "#check if winning state\n",
        "def end_state(test_end_state):\n",
        "    if test_end_state[0] != \" \" and test_end_state[0] == test_end_state[1] and test_end_state[0] == test_end_state[2]:\n",
        "        return True\n",
        "    elif test_end_state[3] != \" \" and test_end_state[3] == test_end_state[4] and test_end_state[3] == test_end_state[5]:\n",
        "        return True\n",
        "    elif test_end_state[6] != \" \" and test_end_state[6] == test_end_state[7] and test_end_state[6] == test_end_state[8]:\n",
        "        return True\n",
        "    elif test_end_state[0] != \" \" and test_end_state[0] == test_end_state[3] and test_end_state[0] == test_end_state[6]:\n",
        "        return True\n",
        "    elif test_end_state[1] != \" \" and test_end_state[1] == test_end_state[4] and test_end_state[1] == test_end_state[7]:\n",
        "        return True\n",
        "    elif test_end_state[2] != \" \" and test_end_state[2] == test_end_state[5] and test_end_state[2] == test_end_state[8]:\n",
        "        return True\n",
        "    elif test_end_state[0] != \" \" and test_end_state[0] == test_end_state[4] and test_end_state[0] == test_end_state[8]:\n",
        "        return True\n",
        "    elif test_end_state[2] != \" \" and test_end_state[2] == test_end_state[4] and test_end_state[6] == test_end_state[2]:\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "#create adjecent states\n",
        "def create_new_states(cur_state, player):\n",
        "    child_states = []\n",
        "    next_player = player\n",
        "    #switch player\n",
        "    if next_player == \"X\":\n",
        "        next_player = \"O\"\n",
        "    else:\n",
        "        next_player = \"X\"\n",
        "    #iterate through all adj states\n",
        "    for i in range(9):\n",
        "        if cur_state[i] == \" \":\n",
        "            #create new state\n",
        "            state_to_be_added = cur_state.copy()\n",
        "            state_to_be_added[i] = player\n",
        "            child_states.append(ticTacToeState(state_to_be_added, next_player, parent=cur_state))\n",
        "    return child_states\n"
      ],
      "metadata": {
        "id": "GWN6rzRGiV1p"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test bfs\n",
        "test_state = ticTacToeState([\"X\",\" \",\" \",\" \", \"X\", \" \", \" \",\" \", \"O\"],\"X\")\n",
        "data = bfs(test_state)\n",
        "with open(\"data.json\", \"w\") as f:\n",
        "    json.dump(list(data), f, indent=1)"
      ],
      "metadata": {
        "id": "zdSJVq2okOUP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q3:\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import Sequential\n",
        "from keras.layers import Flatten, Dense, Dropout\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Normalizing data to become a value between 0 and 1\n",
        "x_train = x_train/255\n",
        "x_test = x_test/255\n",
        "\n",
        "# Setting up model, flattening, setting up layers, using dropout, monitoring accuracy\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(28,28)))\n",
        "model.add(Dense(128,'relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(64, 'relu'))\n",
        "model.add(Dense(10,'Softmax'))\n",
        "model.summary()\n",
        "model.compile(optimizer='Adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, batch_size=128, epochs=5,verbose= 1,shuffle=False,validation_split=0.2)\n",
        "\n",
        "# Calculate Acc, and losses\n",
        "losses, accuracy = model.evaluate(x_test, y_test)\n",
        "print(\"Losses: \", losses)\n",
        "print(\"Accuracy:\", int(accuracy*100),'%')"
      ],
      "metadata": {
        "id": "7XF_-VyE-Fv5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed1e7a01-19f9-4f13-9ea5-8e01be7d69a2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 128)               100480    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 109386 (427.29 KB)\n",
            "Trainable params: 109386 (427.29 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 7s 16ms/step - loss: 0.4460 - accuracy: 0.8719 - val_loss: 0.1827 - val_accuracy: 0.9481\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.1937 - accuracy: 0.9430 - val_loss: 0.1333 - val_accuracy: 0.9607\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1456 - accuracy: 0.9559 - val_loss: 0.1113 - val_accuracy: 0.9681\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1168 - accuracy: 0.9647 - val_loss: 0.1025 - val_accuracy: 0.9693\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1001 - accuracy: 0.9692 - val_loss: 0.0969 - val_accuracy: 0.9707\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0885 - accuracy: 0.9721\n",
            "Losses:  0.08849338442087173\n",
            "Accuracy: 97 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q4\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.preprocessing import StandardScaler # For use in normalizing data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Fetching data from sklearn dataset, this set contains the same data set as seen on keras\n",
        "california_housing = fetch_california_housing(as_frame=True)\n",
        "housing_values = california_housing.frame\n",
        "\n",
        "# Dropping Null values from the table\n",
        "housing_values_final = housing_values.dropna()\n",
        "\n",
        "# Initializing values\n",
        "train_pd, test_pd, val_pd = housing_values_final[:18540], housing_values_final[18540:3708], housing_values_final[3708:]# spliting the data 80% training 20% testing, set some values asside for seperate training set for post training\n",
        "\n",
        "# Numpy Conversions\n",
        "x_train, y_train = train_pd.to_numpy()[:, :-1], train_pd.to_numpy()[:, -1]\n",
        "x_val, y_val = val_pd.to_numpy()[:, :-1], val_pd.to_numpy()[:, -1]\n",
        "x_test, y_test = train_pd.to_numpy()[:, :-1], train_pd.to_numpy()[:, -1]\n",
        "x_train.shape, y_train.shape, x_test.shape, y_test.shape\n",
        "\n",
        "# Normalize data\n",
        "housing_values.head()\n",
        "\n",
        "scaler = StandardScaler().fit(x_train[:, :9]) # Check\n",
        "\n",
        "# Preprocesor for data values\n",
        "def preprocessor(x):\n",
        "  A = np.copy(x)\n",
        "  A[:, :9] = scaler.transform(A[:, :9])\n",
        "  return A\n",
        "\n",
        "x_train, x_test, x_val = preprocessor(x_train), preprocessor(x_test), preprocessor(x_val)\n",
        "x_train.shape, x_test.shape\n",
        "pd.DataFrame(x_train).head()\n",
        "\n",
        "# Set Up model\n",
        "\n",
        "model = Sequential()\n",
        "model.add(InputLayer((8,)))\n",
        "model.add(Dense(128, 'relu'))\n",
        "# model.add(Dropout(0.2))\n",
        "# model.add(Dense(64, 'relu')) # removing lowers loss value by half\n",
        "model.add(Dense(32, 'relu'))\n",
        "model.add(Dense(1, 'linear'))\n",
        "\n",
        "# Regression based loss function\n",
        "\n",
        "opt = Adam(learning_rate=.1)\n",
        "cp = ModelCheckpoint('models/model', save_best_only=True)\n",
        "model.compile(optimizer=opt, loss='mae') # Using MAE due to the values of \"mean house value\" being in format 4.xxx number and not a large number 4xx,xxx in data set\n",
        "model.fit(x_train, y_train, validation_data=(x_val, y_val), callbacks=[cp], epochs=100) # x_val as validation set\n",
        "model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbPxVJ5SGnEi",
        "outputId": "5d04c33d-89e3-4174-befe-e0df0d989a5b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "580/580 [==============================] - 16s 22ms/step - loss: 0.5785 - val_loss: 0.4684\n",
            "Epoch 2/100\n",
            "580/580 [==============================] - 3s 4ms/step - loss: 0.4782 - val_loss: 0.4734\n",
            "Epoch 3/100\n",
            "580/580 [==============================] - 3s 4ms/step - loss: 0.4873 - val_loss: 0.4758\n",
            "Epoch 4/100\n",
            "580/580 [==============================] - 4s 6ms/step - loss: 0.4894 - val_loss: 0.4484\n",
            "Epoch 5/100\n",
            "580/580 [==============================] - 3s 5ms/step - loss: 0.4678 - val_loss: 0.4427\n",
            "Epoch 6/100\n",
            "580/580 [==============================] - 2s 3ms/step - loss: 0.4642 - val_loss: 0.4978\n",
            "Epoch 7/100\n",
            "580/580 [==============================] - 2s 4ms/step - loss: 0.4658 - val_loss: 0.4776\n",
            "Epoch 8/100\n",
            "580/580 [==============================] - 2s 4ms/step - loss: 0.4758 - val_loss: 0.4804\n",
            "Epoch 9/100\n",
            "580/580 [==============================] - 5s 9ms/step - loss: 0.4647 - val_loss: 0.5015\n",
            "Epoch 10/100\n",
            "580/580 [==============================] - 3s 5ms/step - loss: 0.4637 - val_loss: 0.5315\n",
            "Epoch 11/100\n",
            "580/580 [==============================] - 4s 7ms/step - loss: 0.4705 - val_loss: 0.4535\n",
            "Epoch 12/100\n",
            "580/580 [==============================] - 2s 4ms/step - loss: 0.4599 - val_loss: 0.4542\n",
            "Epoch 13/100\n",
            "580/580 [==============================] - 7s 12ms/step - loss: 0.4558 - val_loss: 0.4433\n",
            "Epoch 14/100\n",
            "580/580 [==============================] - 3s 6ms/step - loss: 0.4591 - val_loss: 0.4483\n",
            "Epoch 15/100\n",
            "580/580 [==============================] - 3s 5ms/step - loss: 0.4541 - val_loss: 0.5100\n",
            "Epoch 16/100\n",
            "580/580 [==============================] - 5s 9ms/step - loss: 0.4669 - val_loss: 0.4652\n",
            "Epoch 17/100\n",
            "580/580 [==============================] - 3s 5ms/step - loss: 0.4614 - val_loss: 0.4522\n",
            "Epoch 18/100\n",
            "580/580 [==============================] - 4s 6ms/step - loss: 0.4675 - val_loss: 0.4556\n",
            "Epoch 19/100\n",
            "580/580 [==============================] - 5s 8ms/step - loss: 0.4602 - val_loss: 0.4709\n",
            "Epoch 20/100\n",
            "580/580 [==============================] - 4s 7ms/step - loss: 0.4623 - val_loss: 0.4445\n",
            "Epoch 21/100\n",
            "580/580 [==============================] - 3s 6ms/step - loss: 0.4686 - val_loss: 0.4450\n",
            "Epoch 22/100\n",
            "580/580 [==============================] - 3s 4ms/step - loss: 0.4655 - val_loss: 0.4406\n",
            "Epoch 23/100\n",
            "580/580 [==============================] - 2s 4ms/step - loss: 0.4648 - val_loss: 0.4393\n",
            "Epoch 24/100\n",
            "580/580 [==============================] - 3s 5ms/step - loss: 0.4588 - val_loss: 0.4738\n",
            "Epoch 25/100\n",
            "580/580 [==============================] - 3s 5ms/step - loss: 0.4604 - val_loss: 0.4726\n",
            "Epoch 26/100\n",
            "580/580 [==============================] - 2s 4ms/step - loss: 0.4548 - val_loss: 0.4656\n",
            "Epoch 27/100\n",
            "580/580 [==============================] - 2s 4ms/step - loss: 0.4633 - val_loss: 0.4995\n",
            "Epoch 28/100\n",
            "580/580 [==============================] - 2s 3ms/step - loss: 0.4655 - val_loss: 0.4616\n",
            "Epoch 29/100\n",
            "580/580 [==============================] - 2s 4ms/step - loss: 0.4595 - val_loss: 0.4532\n",
            "Epoch 30/100\n",
            "580/580 [==============================] - 3s 5ms/step - loss: 0.4988 - val_loss: 0.5011\n",
            "Epoch 31/100\n",
            "580/580 [==============================] - 2s 4ms/step - loss: 0.4559 - val_loss: 0.4654\n",
            "Epoch 32/100\n",
            "580/580 [==============================] - 2s 4ms/step - loss: 0.4615 - val_loss: 0.4770\n",
            "Epoch 33/100\n",
            "580/580 [==============================] - 2s 3ms/step - loss: 0.4610 - val_loss: 0.4592\n",
            "Epoch 34/100\n",
            "580/580 [==============================] - 2s 3ms/step - loss: 0.4496 - val_loss: 0.5139\n",
            "Epoch 35/100\n",
            "580/580 [==============================] - 2s 4ms/step - loss: 0.4696 - val_loss: 0.5072\n",
            "Epoch 36/100\n",
            "580/580 [==============================] - 3s 5ms/step - loss: 0.4565 - val_loss: 0.4552\n",
            "Epoch 37/100\n",
            "580/580 [==============================] - 2s 3ms/step - loss: 0.4627 - val_loss: 0.4511\n",
            "Epoch 38/100\n",
            "580/580 [==============================] - 2s 3ms/step - loss: 0.4563 - val_loss: 0.4550\n",
            "Epoch 39/100\n",
            "580/580 [==============================] - 2s 4ms/step - loss: 0.4614 - val_loss: 0.4508\n",
            "Epoch 40/100\n",
            "580/580 [==============================] - 2s 3ms/step - loss: 0.4497 - val_loss: 0.5244\n",
            "Epoch 41/100\n",
            "580/580 [==============================] - 2s 4ms/step - loss: 0.4692 - val_loss: 0.5039\n",
            "Epoch 42/100\n",
            "580/580 [==============================] - 3s 5ms/step - loss: 0.4606 - val_loss: 0.4402\n",
            "Epoch 43/100\n",
            "580/580 [==============================] - 2s 4ms/step - loss: 0.4522 - val_loss: 0.4807\n",
            "Epoch 44/100\n",
            "580/580 [==============================] - 2s 3ms/step - loss: 0.4664 - val_loss: 0.4934\n",
            "Epoch 45/100\n",
            "580/580 [==============================] - 2s 3ms/step - loss: 0.4530 - val_loss: 0.4849\n",
            "Epoch 46/100\n",
            "580/580 [==============================] - 2s 4ms/step - loss: 0.4606 - val_loss: 0.4542\n",
            "Epoch 47/100\n",
            "580/580 [==============================] - 3s 4ms/step - loss: 0.4547 - val_loss: 0.4490\n",
            "Epoch 48/100\n",
            "580/580 [==============================] - 3s 4ms/step - loss: 0.4639 - val_loss: 0.4696\n",
            "Epoch 49/100\n",
            "580/580 [==============================] - 2s 4ms/step - loss: 0.4577 - val_loss: 0.4536\n",
            "Epoch 50/100\n",
            "580/580 [==============================] - 2s 4ms/step - loss: 0.4593 - val_loss: 0.4829\n",
            "Epoch 51/100\n",
            "580/580 [==============================] - 3s 4ms/step - loss: 0.4610 - val_loss: 0.4781\n",
            "Epoch 52/100\n",
            "580/580 [==============================] - 3s 4ms/step - loss: 0.4501 - val_loss: 0.4340\n",
            "Epoch 53/100\n",
            "580/580 [==============================] - 3s 5ms/step - loss: 0.4559 - val_loss: 0.4854\n",
            "Epoch 54/100\n",
            "580/580 [==============================] - 2s 4ms/step - loss: 0.4718 - val_loss: 0.5380\n",
            "Epoch 55/100\n",
            "580/580 [==============================] - 2s 4ms/step - loss: 0.4589 - val_loss: 0.5081\n",
            "Epoch 56/100\n",
            "580/580 [==============================] - 2s 3ms/step - loss: 0.4491 - val_loss: 0.4536\n",
            "Epoch 57/100\n",
            "580/580 [==============================] - 2s 3ms/step - loss: 0.4621 - val_loss: 0.4574\n",
            "Epoch 58/100\n",
            "580/580 [==============================] - 3s 4ms/step - loss: 0.4629 - val_loss: 0.4596\n",
            "Epoch 59/100\n",
            "580/580 [==============================] - 4s 7ms/step - loss: 0.4551 - val_loss: 0.5946\n",
            "Epoch 60/100\n",
            "580/580 [==============================] - 2s 3ms/step - loss: 0.4638 - val_loss: 0.4556\n",
            "Epoch 61/100\n",
            "580/580 [==============================] - 2s 4ms/step - loss: 0.4651 - val_loss: 0.4586\n",
            "Epoch 62/100\n",
            "580/580 [==============================] - 2s 4ms/step - loss: 0.4581 - val_loss: 0.4440\n",
            "Epoch 63/100\n",
            "580/580 [==============================] - 2s 3ms/step - loss: 0.4629 - val_loss: 0.4527\n",
            "Epoch 64/100\n",
            "580/580 [==============================] - 5s 9ms/step - loss: 0.4666 - val_loss: 0.5235\n",
            "Epoch 65/100\n",
            "580/580 [==============================] - 3s 6ms/step - loss: 0.4614 - val_loss: 0.4659\n",
            "Epoch 66/100\n",
            "580/580 [==============================] - 5s 9ms/step - loss: 0.4606 - val_loss: 0.4422\n",
            "Epoch 67/100\n",
            "580/580 [==============================] - 3s 5ms/step - loss: 0.4599 - val_loss: 0.4745\n",
            "Epoch 68/100\n",
            "580/580 [==============================] - 5s 9ms/step - loss: 0.4658 - val_loss: 0.5156\n",
            "Epoch 69/100\n",
            "580/580 [==============================] - 6s 10ms/step - loss: 0.4562 - val_loss: 0.6150\n",
            "Epoch 70/100\n",
            "580/580 [==============================] - 2s 4ms/step - loss: 0.4585 - val_loss: 0.4612\n",
            "Epoch 71/100\n",
            "580/580 [==============================] - 3s 5ms/step - loss: 0.4613 - val_loss: 0.4575\n",
            "Epoch 72/100\n",
            "580/580 [==============================] - 3s 6ms/step - loss: 0.4596 - val_loss: 0.4515\n",
            "Epoch 73/100\n",
            "580/580 [==============================] - 2s 3ms/step - loss: 0.4600 - val_loss: 0.4355\n",
            "Epoch 74/100\n",
            "580/580 [==============================] - 3s 4ms/step - loss: 0.4561 - val_loss: 0.4843\n",
            "Epoch 75/100\n",
            "580/580 [==============================] - 2s 3ms/step - loss: 0.4641 - val_loss: 0.4554\n",
            "Epoch 76/100\n",
            "580/580 [==============================] - 2s 3ms/step - loss: 0.4627 - val_loss: 0.4730\n",
            "Epoch 77/100\n",
            "580/580 [==============================] - 3s 5ms/step - loss: 0.4647 - val_loss: 0.4792\n",
            "Epoch 78/100\n",
            "580/580 [==============================] - 2s 4ms/step - loss: 0.4616 - val_loss: 0.4758\n",
            "Epoch 79/100\n",
            "580/580 [==============================] - 2s 3ms/step - loss: 0.4591 - val_loss: 0.4772\n",
            "Epoch 80/100\n",
            "580/580 [==============================] - 2s 3ms/step - loss: 0.4601 - val_loss: 0.4500\n",
            "Epoch 81/100\n",
            "580/580 [==============================] - 3s 4ms/step - loss: 0.4503 - val_loss: 0.4966\n",
            "Epoch 82/100\n",
            "580/580 [==============================] - 2s 4ms/step - loss: 0.4573 - val_loss: 0.4629\n",
            "Epoch 83/100\n",
            "580/580 [==============================] - 3s 6ms/step - loss: 0.4644 - val_loss: 0.4463\n",
            "Epoch 84/100\n",
            "580/580 [==============================] - 2s 3ms/step - loss: 0.4535 - val_loss: 0.5317\n",
            "Epoch 85/100\n",
            "580/580 [==============================] - 2s 4ms/step - loss: 0.4627 - val_loss: 0.4778\n",
            "Epoch 86/100\n",
            "580/580 [==============================] - 3s 4ms/step - loss: 0.4497 - val_loss: 0.4835\n",
            "Epoch 87/100\n",
            "580/580 [==============================] - 2s 4ms/step - loss: 0.4652 - val_loss: 0.5074\n",
            "Epoch 88/100\n",
            "580/580 [==============================] - 2s 4ms/step - loss: 0.4494 - val_loss: 0.4411\n",
            "Epoch 89/100\n",
            "580/580 [==============================] - 5s 9ms/step - loss: 0.4639 - val_loss: 0.4790\n",
            "Epoch 90/100\n",
            "580/580 [==============================] - 2s 4ms/step - loss: 0.4661 - val_loss: 0.4664\n",
            "Epoch 91/100\n",
            "580/580 [==============================] - 2s 4ms/step - loss: 0.4615 - val_loss: 0.4647\n",
            "Epoch 92/100\n",
            "580/580 [==============================] - 2s 4ms/step - loss: 0.4697 - val_loss: 0.4643\n",
            "Epoch 93/100\n",
            "580/580 [==============================] - 3s 5ms/step - loss: 0.4568 - val_loss: 0.4462\n",
            "Epoch 94/100\n",
            "580/580 [==============================] - 3s 4ms/step - loss: 0.4661 - val_loss: 0.5200\n",
            "Epoch 95/100\n",
            "580/580 [==============================] - 2s 3ms/step - loss: 0.4627 - val_loss: 0.5518\n",
            "Epoch 96/100\n",
            "580/580 [==============================] - 3s 4ms/step - loss: 0.4629 - val_loss: 0.4475\n",
            "Epoch 97/100\n",
            "580/580 [==============================] - 3s 4ms/step - loss: 0.4566 - val_loss: 0.4987\n",
            "Epoch 98/100\n",
            "580/580 [==============================] - 3s 4ms/step - loss: 0.4611 - val_loss: 0.4978\n",
            "Epoch 99/100\n",
            "580/580 [==============================] - 3s 5ms/step - loss: 0.4654 - val_loss: 0.4542\n",
            "Epoch 100/100\n",
            "580/580 [==============================] - 2s 3ms/step - loss: 0.4535 - val_loss: 0.4486\n",
            "580/580 [==============================] - 1s 2ms/step - loss: 0.4383\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4382544457912445"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For predicting purposes\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.metrics import mean_absolute_error as mae\n",
        "model = load_model('models/model')\n",
        "mae(model.predict(x_train), y_train), mae(model.predict(x_val), y_val)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dW6p02UzlsWY",
        "outputId": "72faef38-8e71-43f1-eb61-d7356a7b82a7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "580/580 [==============================] - 1s 2ms/step\n",
            "530/530 [==============================] - 1s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.4251538607318069, 0.4339757483905622)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    }
  ]
}